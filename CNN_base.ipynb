{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_base.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1t0o123aKSNe2iQtGFpsfyqDbNtxu6B4K",
      "authorship_tag": "ABX9TyNMOAbo8u3nYjf2hyYBjv1Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joonyoung-Song/Kaggle-Chest-X-Ray-Images-Pneumonia-/blob/main/CNN_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GybxwKmxcFQU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq4BJRa3KUcl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import np_utils\n",
        "import os\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Ej5Z5NLRem"
      },
      "source": [
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yDVgfLhUzLd"
      },
      "source": [
        "# Define path to the data directory\n",
        "data_dir = Path('drive/MyDrive/Colab Notebooks/kaggle_pneumonia_classification')\n",
        "\n",
        "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
        "train_dir = data_dir / 'train'\n",
        "\n",
        "# Path to validation directory\n",
        "val_dir = data_dir / 'val'\n",
        "\n",
        "# Path to test directory\n",
        "test_dir = data_dir / 'test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T57_3JIMXM3z"
      },
      "source": [
        "# Get the path to the normal and pneumonia sub-directories\n",
        "normal_cases_dir = train_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
        "\n",
        "# Get the list of all the images\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "# An empty list. We will insert the data into this list in (img_path, label) format\n",
        "train_data = []\n",
        "\n",
        "# Go through all the normal cases. The label for these cases will be 0\n",
        "for img in normal_cases:\n",
        "    train_data.append((img,0))\n",
        "\n",
        "# Go through all the pneumonia cases. The label for these cases will be 1\n",
        "for img in pneumonia_cases:\n",
        "    train_data.append((img, 1))\n",
        "\n",
        "# Get a pandas dataframe from the data we have in our list \n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n",
        "\n",
        "# Shuffle the data \n",
        "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "# How the dataframe looks like?\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLo8AApVcHxT"
      },
      "source": [
        "img_size=224\n",
        "X_train = np.zeros(shape=(len(train_data),img_size,img_size,3))\n",
        "\n",
        "for idx,fname in enumerate(tqdm(train_data.image)):\n",
        "  img = image.load_img(fname,target_size=(img_size,img_size))\n",
        "  img_array_train = image.img_to_array(img)\n",
        "  img_array_train = np.expand_dims(img_array_train,axis=0)\n",
        "  X_train[idx] = img_array_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiEO3NzobEDb"
      },
      "source": [
        "# Get the path to the normal and pneumonia sub-directories\n",
        "normal_cases_dir = val_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
        "\n",
        "# Get the list of all the images\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "# An empty list. We will insert the data into this list in (img_path, label) format\n",
        "val_data = []\n",
        "\n",
        "# Go through all the normal cases. The label for these cases will be 0\n",
        "for img in normal_cases:\n",
        "    val_data.append((img,0))\n",
        "\n",
        "# Go through all the pneumonia cases. The label for these cases will be 1\n",
        "for img in pneumonia_cases:\n",
        "    val_data.append((img, 1))\n",
        "\n",
        "# Get a pandas dataframe from the data we have in our list \n",
        "val_data = pd.DataFrame(val_data, columns=['image', 'label'],index=None)\n",
        "\n",
        "# Shuffle the data \n",
        "val_data = val_data.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "# How the dataframe looks like?\n",
        "val_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuDj6Cz9gnKd"
      },
      "source": [
        "img_size=224\n",
        "X_val = np.zeros(shape=(len(val_data),img_size,img_size,3))\n",
        "\n",
        "for idx,fname in enumerate(tqdm(val_data.image)):\n",
        "  img = image.load_img(fname,target_size=(img_size,img_size))\n",
        "  img_array_val = image.img_to_array(img)\n",
        "  img_array_val = np.expand_dims(img_array_val,axis=0)\n",
        "  X_val[idx] = img_array_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDYUc2dZgvxw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MIU-z3IgxZH"
      },
      "source": [
        "# Get the path to the normal and pneumonia sub-directories\n",
        "normal_cases_dir = test_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
        "\n",
        "# Get the list of all the images\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "# An empty list. We will insert the data into this list in (img_path, label) format\n",
        "test_data = []\n",
        "\n",
        "# Go through all the normal cases. The label for these cases will be 0\n",
        "for img in normal_cases:\n",
        "    test_data.append((img,0))\n",
        "\n",
        "# Go through all the pneumonia cases. The label for these cases will be 1\n",
        "for img in pneumonia_cases:\n",
        "    test_data.append((img, 1))\n",
        "\n",
        "# Get a pandas dataframe from the data we have in our list \n",
        "test_data = pd.DataFrame(test_data, columns=['image', 'label'],index=None)\n",
        "\n",
        "# Shuffle the data \n",
        "test_data = test_data.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "# How the dataframe looks like?\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXj8707XgxSs"
      },
      "source": [
        "img_size=224\n",
        "X_test = np.zeros(shape=(len(test_data),img_size,img_size,3))\n",
        "\n",
        "for idx,fname in enumerate(tqdm(test_data.image)):\n",
        "  img = image.load_img(fname,target_size=(img_size,img_size))\n",
        "  img_array_test = image.img_to_array(img)\n",
        "  img_array_test = np.expand_dims(img_array_test,axis=0)\n",
        "  X_test[idx] = img_array_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knBL_zLvgxKF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mYw7iJtgw_N"
      },
      "source": [
        "# CNN 빌드\n",
        "\n",
        "def conv_block(filters):\n",
        "    block = tf.keras.Sequential([\n",
        "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPool2D()\n",
        "    ]\n",
        "    )\n",
        "    \n",
        "    return block\n",
        "\n",
        "def dense_block(units, dropout_rate):\n",
        "    block = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(units, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    \n",
        "    return block\n",
        "\n",
        "def build_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(img_size, img_size, 3)),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPool2D(),\n",
        "        \n",
        "        conv_block(32),\n",
        "        conv_block(64),\n",
        "        \n",
        "        conv_block(128),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        \n",
        "        conv_block(256),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        \n",
        "        tf.keras.layers.Flatten(),\n",
        "        dense_block(512, 0.7),\n",
        "        dense_block(128, 0.5),\n",
        "        dense_block(64, 0.3),\n",
        "        \n",
        "        tf.keras.layers.Dense(2, activation='softmax')\n",
        "        \n",
        "        \n",
        "    ])\n",
        "    model.compile( loss='binary_crossentropy',optimizer='adam',metrics='accuracy')\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbFN89hDABhs"
      },
      "source": [
        "# 모델 밸런싱\n",
        "\n",
        "train_data['label'].value_counts(normalize=True)[0]\n",
        "\n",
        "initial_bias = np.log([train_data['label'].value_counts()[1]/train_data['label'].value_counts()[0]])\n",
        "initial_bias\n",
        "\n",
        "weight_for_0 = (1 / train_data['label'].value_counts()[0])*(len(train_data))/2.0 \n",
        "weight_for_1 = (1 / train_data['label'].value_counts()[1])*(len(train_data))/2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hNw0wVeANh3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model, to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42g67C90Ao4J"
      },
      "source": [
        "y_train=train_data[\"label\"].values\n",
        "y_val=val_data[\"label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW-iwflGAD3w"
      },
      "source": [
        "clf = build_model()\n",
        "\n",
        "es = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=5,\n",
        "                   verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "# rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "#                     patience=3, min_lr=1e-6, mode='min', verbose=1)\n",
        "\n",
        "clf.fit(X_train, \n",
        "        to_categorical(y_train),\n",
        "        validation_data=(X_val, to_categorical(y_val)),\n",
        "        epochs=100,\n",
        "        batch_size=128,\n",
        "        class_weight=class_weight,\n",
        "        callbacks=[es\n",
        "                  #  ,rlr\n",
        "                   ]\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}