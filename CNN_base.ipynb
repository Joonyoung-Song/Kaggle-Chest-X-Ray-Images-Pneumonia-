{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_base.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNVKlOYhL5YSfcRDNlYhNIz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joonyoung-Song/Kaggle-Chest-X-Ray-Images-Pneumonia-/blob/main/CNN_base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bq4BJRa3KUcl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import np_utils\n",
        "import os\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import plot_model, to_categorical\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6Ej5Z5NLRem"
      },
      "source": [
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yDVgfLhUzLd"
      },
      "source": [
        "# Define path to the data directory\n",
        "data_dir = Path('/gdrive/MyDrive/Colab Notebooks/kaggle_pneumonia_classification')\n",
        "\n",
        "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
        "train_dir = data_dir / 'train'\n",
        "\n",
        "# Path to validation directory\n",
        "val_dir = data_dir / 'val'\n",
        "\n",
        "# Path to test directory\n",
        "test_dir = data_dir / 'test'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T57_3JIMXM3z"
      },
      "source": [
        "# Get the path to the normal and pneumonia sub-directories\n",
        "normal_cases_dir = train_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
        "\n",
        "# Get the list of all the images\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "# An empty list. We will insert the data into this list in (img_path, label) format\n",
        "train_data = []\n",
        "\n",
        "# Go through all the normal cases. The label for these cases will be 0\n",
        "for img in normal_cases:\n",
        "    train_data.append((img,0))\n",
        "\n",
        "# Go through all the pneumonia cases. The label for these cases will be 1\n",
        "for img in pneumonia_cases:\n",
        "    train_data.append((img, 1))\n",
        "\n",
        "# Get a pandas dataframe from the data we have in our list \n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n",
        "\n",
        "# Shuffle the data \n",
        "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "# How the dataframe looks like?\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLo8AApVcHxT"
      },
      "source": [
        "img_size=224\n",
        "X_train = np.zeros(shape=(len(train_data),img_size,img_size,3))\n",
        "\n",
        "for idx,fname in enumerate(tqdm(train_data.image)):\n",
        "  img = image.load_img(fname,target_size=(img_size,img_size))\n",
        "  img_array_train = image.img_to_array(img)\n",
        "  img_array_train = np.expand_dims(img_array_train,axis=0)\n",
        "  X_train[idx] = img_array_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiEO3NzobEDb"
      },
      "source": [
        "# Get the path to the normal and pneumonia sub-directories\n",
        "normal_cases_dir = val_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
        "\n",
        "# Get the list of all the images\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "# An empty list. We will insert the data into this list in (img_path, label) format\n",
        "val_data = []\n",
        "\n",
        "# Go through all the normal cases. The label for these cases will be 0\n",
        "for img in normal_cases:\n",
        "    val_data.append((img,0))\n",
        "\n",
        "# Go through all the pneumonia cases. The label for these cases will be 1\n",
        "for img in pneumonia_cases:\n",
        "    val_data.append((img, 1))\n",
        "\n",
        "# Get a pandas dataframe from the data we have in our list \n",
        "val_data = pd.DataFrame(val_data, columns=['image', 'label'],index=None)\n",
        "\n",
        "# Shuffle the data \n",
        "val_data = val_data.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "# How the dataframe looks like?\n",
        "val_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuDj6Cz9gnKd"
      },
      "source": [
        "img_size=224\n",
        "X_val = np.zeros(shape=(len(val_data),img_size,img_size,3))\n",
        "\n",
        "for idx,fname in enumerate(tqdm(val_data.image)):\n",
        "  img = image.load_img(fname,target_size=(img_size,img_size))\n",
        "  img_array_val = image.img_to_array(img)\n",
        "  img_array_val = np.expand_dims(img_array_val,axis=0)\n",
        "  X_val[idx] = img_array_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MIU-z3IgxZH"
      },
      "source": [
        "# Get the path to the normal and pneumonia sub-directories\n",
        "normal_cases_dir = test_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
        "\n",
        "# Get the list of all the images\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "# An empty list. We will insert the data into this list in (img_path, label) format\n",
        "test_data = []\n",
        "\n",
        "# Go through all the normal cases. The label for these cases will be 0\n",
        "for img in normal_cases:\n",
        "    test_data.append((img,0))\n",
        "\n",
        "# Go through all the pneumonia cases. The label for these cases will be 1\n",
        "for img in pneumonia_cases:\n",
        "    test_data.append((img, 1))\n",
        "\n",
        "# Get a pandas dataframe from the data we have in our list \n",
        "test_data = pd.DataFrame(test_data, columns=['image', 'label'],index=None)\n",
        "\n",
        "# Shuffle the data \n",
        "test_data = test_data.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "# How the dataframe looks like?\n",
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXj8707XgxSs"
      },
      "source": [
        "img_size=224\n",
        "X_test = np.zeros(shape=(len(test_data),img_size,img_size,3))\n",
        "\n",
        "for idx,fname in enumerate(tqdm(test_data.image)):\n",
        "  img = image.load_img(fname,target_size=(img_size,img_size))\n",
        "  img_array_test = image.img_to_array(img)\n",
        "  img_array_test = np.expand_dims(img_array_test,axis=0)\n",
        "  X_test[idx] = img_array_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knBL_zLvgxKF"
      },
      "source": [
        "# EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k30oCInJmPO7"
      },
      "source": [
        "print('train set shape :',X_train.shape,train_data['label'].shape)\r\n",
        "print('valid set shape :',X_val.shape,val_data['label'].shape)\r\n",
        "print('test set shape :',X_test.shape,test_data['label'].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCt2tj0xmPKm"
      },
      "source": [
        "plt.bar([\"Pneumonia : 1\",\"Normal : 0\"],train_data['label'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3l3B5YPm5nP"
      },
      "source": [
        "- 폐렴이미지의 수가 3배정도 높은 빈도를 관찰할 수 있음"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_iLAWEXqQ9I"
      },
      "source": [
        "#### train image 관찰하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wq7qQFFKmPFp"
      },
      "source": [
        "#train image 관찰하기\r\n",
        "\r\n",
        "from skimage.io import imread\r\n",
        "\r\n",
        "pneumonia_samples = (train_data[train_data['label']==1]['image'].iloc[:5]).tolist()\r\n",
        "normal_samples = (train_data[train_data['label']==0]['image'].iloc[:5]).tolist()\r\n",
        "\r\n",
        "# Concat the data in a single list and del the above two list\r\n",
        "samples = pneumonia_samples + normal_samples\r\n",
        "del pneumonia_samples, normal_samples\r\n",
        "\r\n",
        "# Plot the data \r\n",
        "f, ax = plt.subplots(2,5, figsize=(30,10))\r\n",
        "for i in range(10):\r\n",
        "    img = imread(samples[i])\r\n",
        "    ax[i//5, i%5].imshow(img, cmap='gray')\r\n",
        "    if i<5:\r\n",
        "        ax[i//5, i%5].set_title(\"Pneumonia\")\r\n",
        "    else:\r\n",
        "        ax[i//5, i%5].set_title(\"Normal\")\r\n",
        "    ax[i//5, i%5].axis('off')\r\n",
        "    ax[i//5, i%5].set_aspect('auto')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri7e9QWRmPBc"
      },
      "source": [
        "- 육안상으로 폐렴 유무를 구분하기 힘듬"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msiCM23mqaW6"
      },
      "source": [
        "#### valid image 관찰하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTPoqSbrqXof"
      },
      "source": [
        "#valid image 관찰하기\r\n",
        "\r\n",
        "from skimage.io import imread\r\n",
        "\r\n",
        "pneumonia_samples = (val_data[train_data['label']==1]['image'].iloc[:5]).tolist()\r\n",
        "normal_samples = (val_data[train_data['label']==0]['image'].iloc[:5]).tolist()\r\n",
        "\r\n",
        "# Concat the data in a single list and del the above two list\r\n",
        "samples = pneumonia_samples + normal_samples\r\n",
        "del pneumonia_samples, normal_samples\r\n",
        "\r\n",
        "# Plot the data \r\n",
        "f, ax = plt.subplots(2,5, figsize=(30,10))\r\n",
        "for i in range(10):\r\n",
        "    img = imread(samples[i])\r\n",
        "    ax[i//5, i%5].imshow(img, cmap='gray')\r\n",
        "    if i<5:\r\n",
        "        ax[i//5, i%5].set_title(\"Pneumonia\")\r\n",
        "    else:\r\n",
        "        ax[i//5, i%5].set_title(\"Normal\")\r\n",
        "    ax[i//5, i%5].axis('off')\r\n",
        "    ax[i//5, i%5].set_aspect('auto')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rUEqGuHrZSE"
      },
      "source": [
        "이미지의 특징\r\n",
        "- 가운데로 모두 정렬되어 있기 때문에 augmentaion 큰 변화 지양\r\n",
        "- 이미지의 좌우상하가 명확함 \r\n",
        "- 이미지의 각도가 일정함\r\n",
        "- 흑백이며 x-ray이기 때문에 밝기도 어느정도 일정함.\r\n",
        "\r\n",
        "=> 이러한 정보를 바탕으로 augmentaion 시도"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3iNeoHkELwq"
      },
      "source": [
        "# Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FwYmfztmHJn"
      },
      "source": [
        "# With data augmentation to prevent overfitting and handling the imbalance in dataset\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "        rescale = 1./255,\r\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\r\n",
        "        samplewise_center=False,  # set each sample mean to 0\r\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\r\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\r\n",
        "        zca_whitening=False,  # apply ZCA whitening\r\n",
        "        rotation_range = 30,  # randomly rotate images in the range (degrees, 0 to 180)\r\n",
        "        zoom_range = 0.2, # Randomly zoom image \r\n",
        "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\r\n",
        "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\r\n",
        "        horizontal_flip = False,  # randomly flip images\r\n",
        "        vertical_flip=False)  # randomly flip images\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz7XxvXqyH0v"
      },
      "source": [
        "- 30도씩 랜덤하게 회전\r\n",
        "- 무작위로 20% 확대/축소\r\n",
        "- 10%만큼 수평으로 이동\r\n",
        "- 10%만큼 수직으로 이동\r\n",
        "- 수평으로 랜덤하게 뒤집기\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZhM9rmEmOdx"
      },
      "source": [
        "datagen.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axVrEcAhmFV2"
      },
      "source": [
        "# Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mYw7iJtgw_N"
      },
      "source": [
        "# CNN 빌드\n",
        "def conv_block(filters):\n",
        "    block = tf.keras.Sequential([\n",
        "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPool2D()\n",
        "    ]\n",
        "    )\n",
        "    return block\n",
        "def dense_block(units, dropout_rate):\n",
        "    block = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(units, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(dropout_rate)\n",
        "    ])\n",
        "    return block\n",
        "def build_model():\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(img_size, img_size, 3)),\n",
        "        \n",
        "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
        "        tf.keras.layers.MaxPool2D(),\n",
        "        \n",
        "        conv_block(32),\n",
        "        conv_block(64),\n",
        "        \n",
        "        conv_block(128),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        \n",
        "        conv_block(256),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        \n",
        "        tf.keras.layers.Flatten(),\n",
        "        dense_block(512, 0.7),\n",
        "        dense_block(128, 0.5),\n",
        "        dense_block(64, 0.3),\n",
        "        \n",
        "        tf.keras.layers.Dense(2, activation='softmax')  \n",
        "    ])\n",
        "    model.compile( loss='binary_crossentropy',optimizer='adam',metrics='accuracy')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbFN89hDABhs"
      },
      "source": [
        "# 모델 밸런싱\n",
        "\n",
        "train_data['label'].value_counts(normalize=True)[0]\n",
        "\n",
        "initial_bias = np.log([train_data['label'].value_counts()[1]/train_data['label'].value_counts()[0]])\n",
        "initial_bias\n",
        "\n",
        "weight_for_0 = (1 / train_data['label'].value_counts()[0])*(len(train_data))/2.0 \n",
        "weight_for_1 = (1 / train_data['label'].value_counts()[1])*(len(train_data))/2.0\n",
        "\n",
        "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
        "\n",
        "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
        "print('Weight for class 1: {:.2f}'.format(weight_for_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42g67C90Ao4J"
      },
      "source": [
        "y_train=train_data[\"label\"].values\n",
        "y_val=val_data[\"label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW-iwflGAD3w"
      },
      "source": [
        "model_dir = data_dir / 'model'\n",
        "checkpoint_path = model_dir / \"cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0.001, patience=10,\n",
        "                   verbose=1, mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "# rlr = ReduceLROnPlateau(monitor='val_loss', patience = 8, verbose=1,factor=0.5, min_lr=0.000001)\n",
        "\n",
        "chkpt = ModelCheckpoint(filepath=checkpoint_path, save_best_only=True, save_weights_only=True)\n",
        "\n",
        "clf = build_model()\n",
        "hist=clf.fit(datagen.flow(X_train, \n",
        "            to_categorical(y_train),batch_size=32),\n",
        "            validation_data=datagen.flow(X_val, to_categorical(y_val)),\n",
        "            epochs=50,\n",
        "            class_weight=class_weight,\n",
        "            callbacks=[es, chkpt \n",
        "                      #  ,rlr\n",
        "                       ]\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4sW5MUOvf4sr"
      },
      "source": [
        "train_acc = hist.history['accuracy']\r\n",
        "val_acc = hist.history['val_accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIti_Cq2f4kN"
      },
      "source": [
        "plt.plot(range(1,len(train_acc)+1),train_acc)\r\n",
        "plt.plot(range(1,len(train_acc)+1),val_acc)\r\n",
        "plt.legend(['train accuracy', 'validation accuracy'],loc=2)\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eaW0dkTAQ6o"
      },
      "source": [
        "clf.load_weights(checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rNA9esU0EkV"
      },
      "source": [
        "clf.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uIAqEftTS8h"
      },
      "source": [
        "loss, acc = clf.evaluate(test_datagen.flow(X_test,  to_categorical(test_data['label'].values)), verbose=2)\r\n",
        "print('정확도: {:5.2f}%'.format(100*acc))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}